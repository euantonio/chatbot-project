
## Tecnologias Utilizadas

- [Python 3](https://www.python.org/): Linguagem base do projeto.
- [Streamlit](https://streamlit.io/): Framework para criar interface gr√°fica.
- [LangChain](https://langchain.readthedocs.io/): Biblioteca para criar fluxos de processamento com LLMs.
- [FAISS](https://faiss.ai/): Busca de informa√ß√µes baseada em similaridade de embeddings.
- [Docker](https://www.docker.com/): Ambiente de cont√™iner para desenvolvimento isolado e reprodut√≠vel.

## Instala√ß√£o

```bash
git clone https://github.com/euantonio/chatbot-project.git
cd chatbot-project
```

Crie um arquivo `.env` na raiz do projeto com sua chave de API da Groq:
```bash
GROQ_API_KEY=SUA_CHAVE_API
```

## Criar cont√™iner Docker

Execute o comando:
```
docker build -t projeto-python .
```

Ap√≥s a cria√ß√£o do cont√™iner, executar:
```
docker run -it projeto-python
```

## üîç Funcionamento do Chatbot

Fluxo Principal:

- O usu√°rio insere uma pergunta.
- O chatbot responde utilizando o modelo configurado (Groq LLM).

Valida√ß√£o de Respostas:

- O projeto inclui uma fun√ß√£o para validar se a resposta gerada √© relevante.

Armazenamento em FAISS:

- As respostas s√£o convertidas em embeddings e armazenadas em um √≠ndice FAISS para buscas futuras.

Hist√≥rico Conversacional:

- Um buffer armazena at√© 5 intera√ß√µes anteriores para manter o contexto da conversa.
